{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d042e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170e9a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): ConvNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): ConvNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       "  (state_dict): MobileNetV3(\n",
       "    (features): Sequential(\n",
       "      (0): ConvNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ConvNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=True)\n",
       "      (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.mobilenet_v3_small(pretrained=False, progress=False, )\n",
    "model.state_dict = torch.load('../model/mobilenet_v3_small.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8e311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "channels = 3\n",
    "height = 1024\n",
    "width = 1024\n",
    "image = cv2.imread('../web/uploads/photo_2022-04-04_16.16.28.jpeg')\n",
    "resized_image = cv2.resize(image, (height, width))\n",
    "transform = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e1d1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.argmax(model.forward(torch.unsqueeze(transform(resized_image), 0)).data).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "238c6d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c48932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e328eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.json', 'r') as f:\n",
    "    classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bed206e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alligator lizard'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[torch.argmax(model.forward(torch.unsqueeze(transform(resized_image), 0)).data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2697f802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%actual_input_1 : Float(1, 3, 1024, 1024, strides=[3145728, 1048576, 1024, 1], requires_grad=0, device=cpu),\n",
      "      %features.1.block.1.fc1.weight : Float(8, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.1.block.1.fc1.bias : Float(8, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.1.block.1.fc2.weight : Float(16, 8, 1, 1, strides=[8, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.1.block.1.fc2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.4.block.2.fc1.weight : Float(24, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.4.block.2.fc1.bias : Float(24, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.4.block.2.fc2.weight : Float(96, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.4.block.2.fc2.bias : Float(96, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.5.block.2.fc1.weight : Float(64, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.5.block.2.fc1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.5.block.2.fc2.weight : Float(240, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.5.block.2.fc2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.6.block.2.fc1.weight : Float(64, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.6.block.2.fc1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.6.block.2.fc2.weight : Float(240, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.6.block.2.fc2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.7.block.2.fc1.weight : Float(32, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.7.block.2.fc1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.7.block.2.fc2.weight : Float(120, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.7.block.2.fc2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.8.block.2.fc1.weight : Float(40, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.8.block.2.fc1.bias : Float(40, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.8.block.2.fc2.weight : Float(144, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.8.block.2.fc2.bias : Float(144, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.9.block.2.fc1.weight : Float(72, 288, 1, 1, strides=[288, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.9.block.2.fc1.bias : Float(72, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.9.block.2.fc2.weight : Float(288, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.9.block.2.fc2.bias : Float(288, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.10.block.2.fc1.weight : Float(144, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.10.block.2.fc1.bias : Float(144, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.10.block.2.fc2.weight : Float(576, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.10.block.2.fc2.bias : Float(576, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.11.block.2.fc1.weight : Float(144, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.11.block.2.fc1.bias : Float(144, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.11.block.2.fc2.weight : Float(576, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.11.block.2.fc2.bias : Float(576, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.0.weight : Float(1024, 576, strides=[576, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.0.bias : Float(1024, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.3.weight : Float(1000, 1024, strides=[1024, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.3.bias : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %421 : Float(16, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %422 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
      "      %424 : Float(16, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %425 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
      "      %427 : Float(16, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %428 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
      "      %430 : Float(72, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %431 : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %433 : Float(72, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %434 : Float(72, strides=[1], requires_grad=0, device=cpu),\n",
      "      %436 : Float(24, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %437 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %439 : Float(88, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %440 : Float(88, strides=[1], requires_grad=0, device=cpu),\n",
      "      %442 : Float(88, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %443 : Float(88, strides=[1], requires_grad=0, device=cpu),\n",
      "      %445 : Float(24, 88, 1, 1, strides=[88, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %446 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %448 : Float(96, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %449 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %451 : Float(96, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %452 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %454 : Float(40, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %455 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
      "      %457 : Float(240, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %458 : Float(240, strides=[1], requires_grad=0, device=cpu),\n",
      "      %460 : Float(240, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %461 : Float(240, strides=[1], requires_grad=0, device=cpu),\n",
      "      %463 : Float(40, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %464 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
      "      %466 : Float(240, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %467 : Float(240, strides=[1], requires_grad=0, device=cpu),\n",
      "      %469 : Float(240, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %470 : Float(240, strides=[1], requires_grad=0, device=cpu),\n",
      "      %472 : Float(40, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %473 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
      "      %475 : Float(120, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %476 : Float(120, strides=[1], requires_grad=0, device=cpu),\n",
      "      %478 : Float(120, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %479 : Float(120, strides=[1], requires_grad=0, device=cpu),\n",
      "      %481 : Float(48, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %482 : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %484 : Float(144, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %485 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %487 : Float(144, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %488 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %490 : Float(48, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %491 : Float(48, strides=[1], requires_grad=0, device=cpu),\n",
      "      %493 : Float(288, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %494 : Float(288, strides=[1], requires_grad=0, device=cpu),\n",
      "      %496 : Float(288, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %497 : Float(288, strides=[1], requires_grad=0, device=cpu),\n",
      "      %499 : Float(96, 288, 1, 1, strides=[288, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %500 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %502 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %503 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %505 : Float(576, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %506 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %508 : Float(96, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %509 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %511 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %512 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %514 : Float(576, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=0, device=cpu),\n",
      "      %515 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %517 : Float(96, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %518 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %520 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %521 : Float(576, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %input.4 : Float(1, 16, 512, 512, strides=[4194304, 262144, 512, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%actual_input_1, %421, %422) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %247 : Float(1, 16, 512, 512, strides=[4194304, 262144, 512, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.4) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %248 : Float(1, 16, 512, 512, strides=[4194304, 262144, 512, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.4, %247) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.12 : Float(1, 16, 256, 256, strides=[1048576, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=16, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%248, %424, %425) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %251 : Float(1, 16, 256, 256, strides=[1048576, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.12) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n",
      "  %input.16 : Float(1, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%251) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.20 : Float(1, 8, 1, 1, strides=[8, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.16, %features.1.block.1.fc1.weight, %features.1.block.1.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.24 : Float(1, 8, 1, 1, strides=[8, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.20) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.28 : Float(1, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.24, %features.1.block.1.fc2.weight, %features.1.block.1.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %256 : Float(1, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.28) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.32 : Float(1, 16, 256, 256, strides=[1048576, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Mul(%256, %251) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %input.40 : Float(1, 16, 256, 256, strides=[1048576, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.32, %427, %428) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.48 : Float(1, 72, 256, 256, strides=[4718592, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.40, %430, %431) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %262 : Float(1, 72, 256, 256, strides=[4718592, 65536, 256, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.48) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n",
      "  %input.56 : Float(1, 72, 128, 128, strides=[1179648, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=72, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%262, %433, %434) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %265 : Float(1, 72, 128, 128, strides=[1179648, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.56) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n",
      "  %input.64 : Float(1, 24, 128, 128, strides=[393216, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%265, %436, %437) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.72 : Float(1, 88, 128, 128, strides=[1441792, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.64, %439, %440) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %270 : Float(1, 88, 128, 128, strides=[1441792, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.72) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n",
      "  %input.80 : Float(1, 88, 128, 128, strides=[1441792, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=88, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %442, %443) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %273 : Float(1, 88, 128, 128, strides=[1441792, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.80) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1440:0\n",
      "  %444 : Float(1, 24, 128, 128, strides=[393216, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%273, %445, %446) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %276 : Float(1, 24, 128, 128, strides=[393216, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%444, %input.64) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py:127:0\n",
      "  %input.92 : Float(1, 96, 128, 128, strides=[1572864, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%276, %448, %449) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %279 : Float(1, 96, 128, 128, strides=[1572864, 16384, 128, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.92) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %280 : Float(1, 96, 128, 128, strides=[1572864, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.92, %279) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.100 : Float(1, 96, 64, 64, strides=[393216, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[2, 2]](%280, %451, %452) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %283 : Float(1, 96, 64, 64, strides=[393216, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.100) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %284 : Float(1, 96, 64, 64, strides=[393216, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.100, %283) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.104 : Float(1, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%284) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.108 : Float(1, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.104, %features.4.block.2.fc1.weight, %features.4.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.112 : Float(1, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.108) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.116 : Float(1, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.112, %features.4.block.2.fc2.weight, %features.4.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %289 : Float(1, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.116) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.120 : Float(1, 96, 64, 64, strides=[393216, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%289, %284) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %input.128 : Float(1, 40, 64, 64, strides=[163840, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.120, %454, %455) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.136 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.128, %457, %458) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %295 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.136) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %296 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.136, %295) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.144 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=240, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%296, %460, %461) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %299 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.144) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %300 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.144, %299) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.148 : Float(1, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%300) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.152 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.148, %features.5.block.2.fc1.weight, %features.5.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.156 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.152) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.160 : Float(1, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.156, %features.5.block.2.fc2.weight, %features.5.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %305 : Float(1, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.160) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.164 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%305, %300) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %462 : Float(1, 40, 64, 64, strides=[163840, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.164, %463, %464) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %309 : Float(1, 40, 64, 64, strides=[163840, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%462, %input.128) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py:127:0\n",
      "  %input.176 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%309, %466, %467) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %312 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.176) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %313 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.176, %312) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.184 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=240, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%313, %469, %470) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %316 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.184) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %317 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.184, %316) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.188 : Float(1, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%317) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.192 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.188, %features.6.block.2.fc1.weight, %features.6.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.196 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.192) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.200 : Float(1, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.196, %features.6.block.2.fc2.weight, %features.6.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %322 : Float(1, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.200) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.204 : Float(1, 240, 64, 64, strides=[983040, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%322, %317) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %471 : Float(1, 40, 64, 64, strides=[163840, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.204, %472, %473) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %326 : Float(1, 40, 64, 64, strides=[163840, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%471, %309) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py:127:0\n",
      "  %input.216 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%326, %475, %476) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %329 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.216) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %330 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.216, %329) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.224 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=120, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%330, %478, %479) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %333 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.224) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %334 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.224, %333) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.228 : Float(1, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%334) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.232 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.228, %features.7.block.2.fc1.weight, %features.7.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.236 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.232) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.240 : Float(1, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.236, %features.7.block.2.fc2.weight, %features.7.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %339 : Float(1, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.240) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.244 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%339, %334) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %input.252 : Float(1, 48, 64, 64, strides=[196608, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.244, %481, %482) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.260 : Float(1, 144, 64, 64, strides=[589824, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.252, %484, %485) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %345 : Float(1, 144, 64, 64, strides=[589824, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.260) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %346 : Float(1, 144, 64, 64, strides=[589824, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.260, %345) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.268 : Float(1, 144, 64, 64, strides=[589824, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%346, %487, %488) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %349 : Float(1, 144, 64, 64, strides=[589824, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.268) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %350 : Float(1, 144, 64, 64, strides=[589824, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.268, %349) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.272 : Float(1, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%350) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.276 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.272, %features.8.block.2.fc1.weight, %features.8.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.280 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.276) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.284 : Float(1, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.280, %features.8.block.2.fc2.weight, %features.8.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %355 : Float(1, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.284) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.288 : Float(1, 144, 64, 64, strides=[589824, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%355, %350) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %489 : Float(1, 48, 64, 64, strides=[196608, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.288, %490, %491) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %359 : Float(1, 48, 64, 64, strides=[196608, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%489, %input.252) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py:127:0\n",
      "  %input.300 : Float(1, 288, 64, 64, strides=[1179648, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%359, %493, %494) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %362 : Float(1, 288, 64, 64, strides=[1179648, 4096, 64, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.300) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %363 : Float(1, 288, 64, 64, strides=[1179648, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.300, %362) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.308 : Float(1, 288, 32, 32, strides=[294912, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=288, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[2, 2]](%363, %496, %497) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %366 : Float(1, 288, 32, 32, strides=[294912, 1024, 32, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.308) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %367 : Float(1, 288, 32, 32, strides=[294912, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.308, %366) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.312 : Float(1, 288, 1, 1, strides=[288, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%367) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.316 : Float(1, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.312, %features.9.block.2.fc1.weight, %features.9.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.320 : Float(1, 72, 1, 1, strides=[72, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.316) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.324 : Float(1, 288, 1, 1, strides=[288, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.320, %features.9.block.2.fc2.weight, %features.9.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %372 : Float(1, 288, 1, 1, strides=[288, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.324) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.328 : Float(1, 288, 32, 32, strides=[294912, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%372, %367) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %input.336 : Float(1, 96, 32, 32, strides=[98304, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.328, %499, %500) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.344 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.336, %502, %503) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %378 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.344) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %379 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.344, %378) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.352 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%379, %505, %506) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %382 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.352) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %383 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.352, %382) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.356 : Float(1, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%383) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.360 : Float(1, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.356, %features.10.block.2.fc1.weight, %features.10.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.364 : Float(1, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.360) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.368 : Float(1, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.364, %features.10.block.2.fc2.weight, %features.10.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %388 : Float(1, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.368) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.372 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%388, %383) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %507 : Float(1, 96, 32, 32, strides=[98304, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.372, %508, %509) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %392 : Float(1, 96, 32, 32, strides=[98304, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Add(%507, %input.336) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py:127:0\n",
      "  %input.384 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%392, %511, %512) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %395 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.384) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %396 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.384, %395) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.392 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%396, %514, %515) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %399 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.392) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %400 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.392, %399) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %input.396 : Float(1, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%400) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %input.400 : Float(1, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.396, %features.11.block.2.fc1.weight, %features.11.block.2.fc1.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %input.404 : Float(1, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Relu(%input.400) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1442:0\n",
      "  %input.408 : Float(1, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.404, %features.11.block.2.fc2.weight, %features.11.block.2.fc2.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %405 : Float(1, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=1, device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.408) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1967:0\n",
      "  %input.412 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%405, %400) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/ops/misc.py:163:0\n",
      "  %516 : Float(1, 96, 32, 32, strides=[98304, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%input.412, %517, %518) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %409 : Float(1, 96, 32, 32, strides=[98304, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Add(%516, %392) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py:127:0\n",
      "  %input.424 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%409, %520, %521) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:0\n",
      "  %412 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.424) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %413 : Float(1, 576, 32, 32, strides=[589824, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.424, %412) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %414 : Float(1, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%413) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1241:0\n",
      "  %415 : Float(1, 576, strides=[576, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%414) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torchvision/models/mobilenetv3.py:227:0\n",
      "  %input.428 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%415, %classifier.0.weight, %classifier.0.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %417 : Float(1, 1024, strides=[1024, 1], device=cpu) = onnx::HardSigmoid[alpha=0.16666666666666666](%input.428) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %418 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::Mul(%input.428, %417) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2074:0\n",
      "  %output1 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%418, %classifier.3.weight, %classifier.3.bias) # /Users/19065443/miniconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  return (%output1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, channels, height, width)\n",
    "\n",
    "input_names = [ \"actual_input_1\" ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"mobilenet_v3_small.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af65b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"mobilenet_v3_small.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53b866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
